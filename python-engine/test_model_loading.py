#!/usr/bin/env python3
"""
Whisper æ¨¡å‹åŠ è½½æµ‹è¯•

ç›®çš„ï¼šéªŒè¯ faster-whisper å’Œ PyTorch æ˜¯å¦èƒ½æ­£å¸¸å·¥ä½œ
"""

import sys
from faster_whisper import WhisperModel

def test_model_loading():
    """æµ‹è¯• Whisper æ¨¡å‹æ˜¯å¦èƒ½æ­£å¸¸åŠ è½½"""

    print("=" * 60)
    print("Whisper æ¨¡å‹åŠ è½½æµ‹è¯•")
    print("=" * 60)
    print()

    # æ¨¡å‹é…ç½®
    model_size = "medium"  # å¯é€‰: tiny, base, small, medium, large

    print(f"ğŸ“¦ æ¨¡å‹å¤§å°: {model_size}")
    print(f"ğŸ”„ æ­£åœ¨åŠ è½½æ¨¡å‹...")
    print()

    try:
        # åŠ è½½æ¨¡å‹
        # é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹æ–‡ä»¶ï¼ˆçº¦ 1.5 GBï¼‰
        model = WhisperModel(
            model_size,
            device="cpu",  # Apple Silicon ä¸Šçš„ä¼˜åŒ–
            compute_type="float32"  # æˆ– "int8" ä»¥èŠ‚çœå†…å­˜
        )

        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
        print()
        print("ğŸ“Š æ¨¡å‹ä¿¡æ¯:")
        print(f"   - æ¨¡å‹ç±»å‹: {model_size}")
        print(f"   - è®¾å¤‡: CPU")
        print(f"   - è®¡ç®—ç±»å‹: float32")
        print()
        print("ğŸ‰ faster-whisper å’Œ PyTorch å·¥ä½œæ­£å¸¸ï¼")
        print()
        print("ä¸‹ä¸€æ­¥ï¼šè¿è¡Œ test_transcription.py æµ‹è¯•éŸ³é¢‘è½¬å½•")
        print()

        return True

    except Exception as e:
        print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼")
        print()
        print(f"é”™è¯¯ä¿¡æ¯: {e}")
        print()
        print("è¯·æ£€æŸ¥:")
        print("  1. ç½‘ç»œè¿æ¥ï¼ˆé¦–æ¬¡éœ€è¦ä¸‹è½½æ¨¡å‹ï¼‰")
        print("  2. ç£ç›˜ç©ºé—´ï¼ˆè‡³å°‘éœ€è¦ 2 GBï¼‰")
        print("  3. Python è™šæ‹Ÿç¯å¢ƒæ˜¯å¦æ¿€æ´»")
        print()

        return False


if __name__ == "__main__":
    success = test_model_loading()
    sys.exit(0 if success else 1)
